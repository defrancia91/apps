{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "streamlit>=1.26.0\n",
        "streamlit-feedback\n",
        "pypdf\n",
        "pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuA-VP0lUZwi",
        "outputId": "c5b4b0af-634e-4774-e092-6e57853aa8d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "id": "Zyv5GHFFUbGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef3a862-ac99-4a15-865d-e7eb254a7d6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiNLQEAsUGNF",
        "outputId": "998ba309-55a0-46ae-dbb4-1c7938262c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ER_analysis_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ER_analysis_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pypdf\n",
        "import json\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Function to read PDF and extract text\n",
        "def read_pdf(file):\n",
        "\t  pages = []\n",
        "\t  pdf = pypdf.PdfReader(file)\n",
        "\t  for p in range(len(pdf.pages)):\n",
        "\t\t  page = pdf.pages[p]\n",
        "\t\t  text = page.extract_text()\n",
        "\t\t  pages += [text]\n",
        "\t  return pages\n",
        "\n",
        "# Set layout\n",
        "st.set_page_config(page_title=\"Earning Release Analyst\", layout=\"wide\")\n",
        "\n",
        "# Set Title\n",
        "st.title(\"ğŸ“ Earning Release Analyst\")\n",
        "\n",
        "# Set Sidebar\n",
        "with st.sidebar:\n",
        "  hf_api_key = st.text_input(\"Enter your Hugging Face API key\", type=\"password\")\n",
        "  ngrok_auth_token = st.text_input(\"Enter your NGROK token\", type=\"password\")\n",
        "\n",
        "# Upload the file\n",
        "uploaded_file = st.file_uploader(\"Upload a file\", type=(\"txt\", \"md\", \"pdf\"))\n",
        "\n",
        "\n",
        "if uploaded_file and hf_api_key and ngrok_auth_token:\n",
        "\n",
        "    # Parse the file\n",
        "    if uploaded_file.type == \"application/pdf\":\n",
        "        article = read_pdf(uploaded_file)\n",
        "    else:\n",
        "        article = uploaded_file.read().decode()\n",
        "\n",
        "    # Prompt for LLM\n",
        "    prompt = f\"\"\"\n",
        "    Act as a company financial analyst to analyze the earnings releases of companies,\n",
        "    delimited below by triple backticks.\n",
        "\n",
        "    Output should include:\n",
        "\n",
        "    - Overall sentiment: <positive, negative or neutral; keeping in mind that companies will often appear to be extremely optimistic about their company performance>\n",
        "    - Key words: <find those words which are most repeated and drivers of growth and performance for the company, include 7 words max>\n",
        "    - Executive summary: <executive summary of past performance and about which will be drivers for next earnings in the future, 10 lines max>\n",
        "\n",
        "    Keep all information factual and only include information extracted from the earning release document.\n",
        "\n",
        "    Earning release document:\n",
        "    ```{article}```\n",
        "    \"\"\"\n",
        "\n",
        "    # Define query function\n",
        "    def query(payload, model_api_url):\n",
        "        headers = {\"Authorization\": f\"Bearer {hf_api_key}\"}\n",
        "        response = requests.post(model_api_url, headers=headers, json=payload)\n",
        "        return response.json()\n",
        "\n",
        "    # LLM model parameters\n",
        "    mistral_api_url = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "    mistral_params = {\n",
        "                  \"wait_for_model\": True,\n",
        "                  \"do_sample\": False,\n",
        "                  \"return_full_text\": False,\n",
        "                  \"max_new_tokens\": 5000,\n",
        "                  \"repetition_penalty\": 1.5,\n",
        "                  \"temperature\": 0.001\n",
        "                }\n",
        "\n",
        "    # LLM model request\n",
        "    output = query(payload={\"inputs\": prompt, \"parameters\": mistral_params}, model_api_url=mistral_api_url)\n",
        "\n",
        "    # Display result\n",
        "    st.write(\"### Answer\")\n",
        "    st.write(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/ER_analysis_app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "iAYHlV9_Umtc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ngrok\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken using Google Secrets\n",
        "ngrok_auth_token = userdata.get('NGROK_KEY')\n",
        "ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "# Open an HTTPs tunnel on port XXXX which you get from your `logs.txt` file\n",
        "ngrok_tunnel = ngrok.connect(addr=\"8505\", proto=\"http\", bind_tls=True)\n",
        "print(\"Streamlit App:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxiXlppAUezV",
        "outputId": "e17b28fd-d3ee-4585-e852-77b2de991c81"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit App: https://84a3-35-194-79-254.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "8-oDSDag8FVI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eL7t-Gsl8Gqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}